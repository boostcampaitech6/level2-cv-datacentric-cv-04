{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b14d3ff-9390-403a-9329-8eb97c9def22",
   "metadata": {},
   "source": [
    "# Ensemble - WBF\n",
    "utils 폴더안에 해당 주피터파일 위치해서 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59dbe882-5065-459a-9e76-663dd1346cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2202403/1171383838.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from weighted_boxes_fusion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d14d3e-6b88-45db-8ee0-5066e63923db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = \"../../data/medical/img/test/\"\n",
    "get_img_files = os.listdir(test_folder)\n",
    "# if get_img_files[-1].startswith('.'):  # '.'으로 시작하는 파일 제거용\n",
    "#     get_img_files.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea0467d9-a80b-48f8-9244-f9c7788d03f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_img_files) # 100개 뜨면 정상"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e7bb462-405f-433b-a2d8-743adbbcceee",
   "metadata": {},
   "source": [
    "## COCO format test.json 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9080f8-0dfc-45c6-86c5-26edba856b76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# coco_data = {\n",
    "#         \"images\": [],\n",
    "#         \"annotations\": [],\n",
    "#         \"categories\": [{\"id\": 1, \"name\": \"text\"}],    # 이부분은 비워놔도 됨(only text)\n",
    "# }\n",
    "\n",
    "# for i, test_file in enumerate(get_img_files):\n",
    "#     img = cv2.imread(test_folder+test_file)\n",
    "#     h, w, c = img.shape\n",
    "#     coco_image = {\n",
    "#             \"id\": i,\n",
    "#             \"width\": w,\n",
    "#             \"height\": h,\n",
    "#             \"file_name\": test_file,\n",
    "#             \"license\": 0, \n",
    "#             \"flickr_url\": None, \n",
    "#             \"coco_url\": None, \n",
    "#             \"date_captured\": None\n",
    "#     }\n",
    "#     coco_data[\"images\"].append(coco_image)\n",
    "\n",
    "# with open('../../data/medical/ufo/test.json', 'w') as f:\n",
    "#     json.dump(coco_data, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3507144f-e243-49b7-972e-a7e1da2fc30c",
   "metadata": {},
   "source": [
    "## 앙상블 시작\n",
    "code/utils/ensemble/~.json 파일들 두기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bb941",
   "metadata": {},
   "source": [
    "#### recipe 1\n",
    "- recipe1 : 노이즈에 취약, 후라이 까는거 보정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da19957c-d46b-47d1-96b5-09e427428b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_files = [\"output200_kim.json\", \"output250_kim.json\", \"output300_kang.json\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38dc24",
   "metadata": {},
   "source": [
    "#### recipe 2\n",
    "- recipe2 : 노이즈 개선(FP 감소), FN 증가(+세로박스) -> FN 증가 이유는 합친 모델이 2개라서 둘 중에 하나라도 안되어 있으면 없앰."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "218e998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_files = [\"output200_kim.json\", \"output300_kang.json\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7db5ea",
   "metadata": {},
   "source": [
    "#### recipe 3\n",
    "- recipe3 : recipe2에서 FN 개선(세로 박스도 무난히 잡음) -> recipe1에서 간간히 큐알 코드를 검출하던 문제가 해결됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83acd224",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_files = [\"output200_kim.json\", \"output300_kang.json\", \"output165_lee.json\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adacdd6e",
   "metadata": {},
   "source": [
    "#### recipe 4\n",
    "- recipe3 대비 노이즈에 조금 더 취약해짐, FN 또한 살짝 증가된 것으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf4fe739",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_files = [\"output240_messi.json\", \"output300_kang.json\", \"output165_lee.json\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1dfe2",
   "metadata": {},
   "source": [
    "#### recipe 5\n",
    "- recipe4에서 증가되었던 FN이 개선됨. 하지만 노이즈는 개선이 되지 않아서 노이즈를 개선 시켜줄 모델이 하나 더 필요함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d48a13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_files = [\"output200_kim.json\", \"output240_messi.json\", \"output300_kang.json\", \"output165_lee.json\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfee843",
   "metadata": {},
   "source": [
    "#### recipe 6\n",
    "- recipe5의 문제였던 노이즈 개선됨. 하지만 개선된 FN도 아주 살짝 증가함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a7975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_files = [\"output200_kim.json\", \"output240_messi.json\", \"output165_lee.json\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1792f",
   "metadata": {},
   "source": [
    "#### recipe 7\n",
    "- recipe5에서 output160_lee.json -> output180_lee.json으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b877718",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_files = [\"output200_kim.json\", \"output240_messi.json\", \"output300_kang.json\", \"output180_lee.json\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68973f12",
   "metadata": {},
   "source": [
    "#### recipe 8\n",
    "- recipe6에서 output160_lee.json -> output180_lee.json으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b948de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_files = [\"output200_kim.json\", \"output240_messi.json\", \"output180_lee.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d55b9d8-7361-4928-b8bb-288026edaea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/level2-cv-datacentric-cv-04/CSH/utils/wbf_ensemble.py:45: UserWarning: X1 < 0 in box. Set it to 0.\n",
      "  warnings.warn(\"X1 < 0 in box. Set it to 0.\")\n",
      "/data/ephemeral/home/level2-cv-datacentric-cv-04/CSH/utils/wbf_ensemble.py:61: UserWarning: Y1 < 0 in box. Set it to 0.\n",
      "  warnings.warn(\"Y1 < 0 in box. Set it to 0.\")\n",
      "/data/ephemeral/home/level2-cv-datacentric-cv-04/CSH/utils/wbf_ensemble.py:56: UserWarning: X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/level2-cv-datacentric-cv-04/CSH/utils/wbf_ensemble.py:72: UserWarning: Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "annotation = '../../data/medical/ufo/test.json'\n",
    "coco = COCO(annotation)\n",
    "\n",
    "iou_thr = 0.5            # TODO : iou threshold 설정\n",
    "skip_box_thr = 0.0001    # TODO : skip iou threshold 설정 0.0001\n",
    "\n",
    "images_anno = {}\n",
    "for i, test_file in enumerate(get_img_files):\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    labels_list = []\n",
    "    image_info = coco.loadImgs(i)[0]\n",
    "    \n",
    "    for submission in submission_files:\n",
    "        with open('./ensemble/'+submission, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            images = data['images']\n",
    "        words = images[image_info['file_name']]\n",
    "        box_list = []\n",
    "        for word_id, word_data in words[\"words\"].items():\n",
    "            # UFO to PascalVOC format\n",
    "            [tl, tr, br, bl] = word_data[\"points\"]\n",
    "            xmin = min(tl[0], tr[0], br[0], bl[0])\n",
    "            ymin = min(tl[1], tr[1], br[1], bl[1])\n",
    "            xmax = max(tl[0], tr[0], br[0], bl[0])\n",
    "            ymax = max(tl[1], tr[1], br[1], bl[1])\n",
    "            box = [xmin/image_info['width'], ymin/image_info['height'], xmax/image_info['width'], ymax/image_info['height']]\n",
    "            box_list.append(box)\n",
    "        boxes_list.append(box_list)\n",
    "        scores_list.append([1.0]*len(words[\"words\"].items()))\n",
    "        labels_list.append([1]*len(words[\"words\"].items()))\n",
    "\n",
    "    if len(boxes_list):\n",
    "        boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "        prediction_words = []\n",
    "        points_list = []\n",
    "        for idx, (box, score, label) in enumerate(zip(boxes, scores, labels)):\n",
    "            # PascalVOC to UFO format\n",
    "            p_xmin = box[0]*image_info['width']\n",
    "            p_ymin = box[1]*image_info['height']\n",
    "            p_xmax = box[2]*image_info['width']\n",
    "            p_ymax = box[3]*image_info['height']\n",
    "            p_width = p_xmax - p_xmin\n",
    "            p_height = p_ymax - p_ymin\n",
    "            p_tl = [p_xmin, p_ymin]\n",
    "            p_tr = [p_xmin + p_width, p_ymin]\n",
    "            p_br = [p_xmin + p_width, p_ymin + p_height]\n",
    "            p_bl = [p_xmin, p_ymin + p_height]\n",
    "            points = [p_tl, p_tr, p_br, p_bl]\n",
    "            points_list.append(points)\n",
    "        prediction_words = {idx: dict(points=p) for idx, p in enumerate(points_list)}\n",
    "    images_anno[image_info['file_name']] = dict(words=prediction_words)\n",
    "\n",
    "images_anno = {'images':images_anno}\n",
    "# 앙상블 결과 출력용\n",
    "with open('ensemble/result.json', 'w') as f:\n",
    "    json.dump(images_anno, f)\n",
    "\n",
    "# 제출용 : csv 파일로 바로 변경\n",
    "with open('ensemble/result.csv', 'w') as f:\n",
    "    json.dump(images_anno, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1d2f735-72d7-4fc5-a68a-0049e602aea3",
   "metadata": {},
   "source": [
    "## 앙상블 결과 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776aae0b-4bdb-42d4-bd12-e183ada7d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../../data/medical/img/test/'\n",
    "anno_root = './ensemble/result.json'\n",
    "\n",
    "bboxes = []\n",
    "\n",
    "with open(anno_root, 'r') as f:\n",
    "    train_json = json.load(f)\n",
    "    images = train_json['images']\n",
    "    images_df = pd.DataFrame.from_dict(images)\n",
    "\n",
    "image_id = list(images_df)\n",
    "fnames = [os.path.join(root_path, i) for i in image_id]\n",
    "\n",
    "for index, img_id in enumerate(image_id):\n",
    "    temp_anns = []\n",
    "\n",
    "    temp = images_df[f'{img_id}']\n",
    "    words = temp.loc['words']\n",
    "\n",
    "    for key in words.keys():\n",
    "        temp_ann = {}\n",
    "        temp_ann['image_id'] = img_id \n",
    "        temp_ann['id'] = index\n",
    "\n",
    "        word = words[key]\n",
    "\n",
    "        temp_ann['bbox'] = word['points']\n",
    "        temp_anns.append(temp_ann)\n",
    "    bboxes.append(temp_anns)\n",
    "\n",
    "img_name_list = [img.split(\"/\")[-1][:-4] for img in fnames]\n",
    "\n",
    "def showimg(idx):\n",
    "    fig, ax = plt.subplots(1, 2, dpi=512)\n",
    "    img = io.imread(fnames[idx])\n",
    "\n",
    "    anns = bboxes[idx]\n",
    "    \n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(img)\n",
    "\n",
    "    for ann in anns:\n",
    "        ann_id = ann['id']\n",
    "        #class_idx = ann['category_id']\n",
    "        \n",
    "        ax[0].set_title('original', fontsize = 7)\n",
    "        ax[1].set_title(f\"{img_name_list[idx]}\", fontsize = 7)\n",
    "        \n",
    "        ax[0].set_xticks([])\n",
    "        ax[0].set_yticks([])\n",
    "        \n",
    "        ax[1].set_xticks([])\n",
    "        ax[1].set_yticks([])\n",
    "        \n",
    "        for pos in ['right', 'top', 'bottom', 'left']:\n",
    "            ax[0].spines[pos].set_visible(False)\n",
    "            ax[1].spines[pos].set_visible(False)\n",
    "            \n",
    "        points = np.array(ann['bbox'])\n",
    "        ax[1].add_patch(patches.Polygon(\n",
    "            points,\n",
    "            closed = True,\n",
    "            edgecolor = 'orange',\n",
    "            fill = False,\n",
    "            linewidth = 0.3\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee462b9b-2eab-4f8a-bddd-7173de450f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [8,9,12,14,16,18,25,26,27,29,32,37,41,42,43,44,45,51,52,53,55,62,63,69,84,92,93,97]: # index 0~99\n",
    "    showimg(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
